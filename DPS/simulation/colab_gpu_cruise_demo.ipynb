{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cruise Control GPU (Live Mirror)\n",
    "\n",
    "This notebook mirrors your local **CPU cruise-control** data on the GPU in real-time.\n",
    "It uses only log streaming (no C code changes).\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch, time, requests\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Device:', device)\n",
    "if device.type == 'cuda':\n",
    "    print('GPU:', torch.cuda.get_device_name(0))\n",
    "\n",
    "# Match C constants\n",
    "SIM_DT = 0.1\n",
    "TARGET_GAP = 10.0\n",
    "Kp = 0.35\n",
    "Kd = 0.70\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "def compute_block(sample, device):\n",
    "    row = [[\n",
    "        sample['my_x'], sample['my_y'],\n",
    "        sample['leader_x'], sample['leader_y'],\n",
    "        sample['current_speed'], sample['leader_speed'], sample['leader_speed']\n",
    "    ]]\n",
    "    d = torch.tensor(row, dtype=torch.float32, device=device)\n",
    "    my_x, my_y, front_x, front_y, cur_spd, front_spd, leader_spd = d.T\n",
    "    gap = torch.sqrt((my_x - front_x)**2 + (my_y - front_y)**2)\n",
    "    projected_error = (gap - TARGET_GAP) - (front_spd * SIM_DT)\n",
    "    base = leader_spd\n",
    "    damping = (front_spd - cur_spd) * Kd\n",
    "    correction = projected_error * Kp\n",
    "    new_speed = base + damping + correction\n",
    "    new_speed = torch.maximum(new_speed, torch.zeros_like(base))\n",
    "    new_speed = torch.minimum(new_speed, base + 25.0)\n",
    "\n",
    "    # Optional: time-to-collision (TTC)\n",
    "    rel = cur_spd - front_spd\n",
    "    eps = 1e-6\n",
    "    inf = torch.tensor(float('inf'), device=device)\n",
    "    ttc = torch.where(rel > eps, gap / rel, inf)\n",
    "\n",
    "    return gap.item(), new_speed.item(), ttc.item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rajdeep\n",
    "# Intruder GPU model (1000x1000 grid)\n",
    "GRID_SIZE = 1000\n",
    "GRID_OFFSET = GRID_SIZE // 2\n",
    "INTRUDER_RADIUS = 4\n",
    "INTRUDER_PROB = 0.05\n",
    "INTRUDER_SPEED = 40\n",
    "INTRUDER_LENGTH = 10\n",
    "INTRUDER_DURATION_MS = 5000\n",
    "\n",
    "intruder_grid = torch.zeros((GRID_SIZE, GRID_SIZE), device=device)\n",
    "\n",
    "def _grid_idx(v):\n",
    "    return max(0, min(GRID_SIZE - 1, int(round(v)) + GRID_OFFSET))\n",
    "\n",
    "def gpu_intruder_scan(sample):\n",
    "    intruder_grid.zero_()\n",
    "    fx = sample['my_x']\n",
    "    fy = sample['my_y']\n",
    "    fx_i = _grid_idx(fx)\n",
    "    fy_i = _grid_idx(fy)\n",
    "\n",
    "    # Spawn near truck with small probability\n",
    "    if torch.rand((), device=device).item() > INTRUDER_PROB:\n",
    "        return False\n",
    "\n",
    "    ox = int(torch.randint(-INTRUDER_RADIUS, INTRUDER_RADIUS + 1, (1,), device=device).item())\n",
    "    oy = int(torch.randint(-INTRUDER_RADIUS, INTRUDER_RADIUS + 1, (1,), device=device).item())\n",
    "    ix = max(0, min(GRID_SIZE - 1, fx_i + ox))\n",
    "    iy = max(0, min(GRID_SIZE - 1, fy_i + oy))\n",
    "\n",
    "    intruder_grid[ix, iy] = 1.0\n",
    "\n",
    "    x0 = max(0, fx_i - INTRUDER_RADIUS)\n",
    "    x1 = min(GRID_SIZE, fx_i + INTRUDER_RADIUS + 1)\n",
    "    y0 = max(0, fy_i - INTRUDER_RADIUS)\n",
    "    y1 = min(GRID_SIZE, fy_i + INTRUDER_RADIUS + 1)\n",
    "\n",
    "    hit = intruder_grid[x0:x1, y0:y1].sum() > 0\n",
    "    return bool(hit)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Live URL\n",
    "Paste your tunnel URL here (cloudflared).\n",
    "Example: `https://abc.trycloudflare.com/latest.json`\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "LIVE_URL = \"https://meter-injection-tiny-sec.trycloudflare.com/latest.json\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INTRUDER_POST_URL = LIVE_URL.rsplit('/', 1)[0] + '/intruder'\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Rajdeep\n",
    "seq = 0\n",
    "null_shown = {}\n",
    "for _ in range(2000):\n",
    "    try:\n",
    "        r = requests.get(LIVE_URL, timeout=5)\n",
    "        if r.status_code != 200 or not r.text.strip():\n",
    "            print('Waiting for live JSON...')\n",
    "            time.sleep(0.5)\n",
    "            continue\n",
    "        s = r.json()\n",
    "    except Exception as e:\n",
    "        print('Waiting for live JSON...', e)\n",
    "        time.sleep(0.5)\n",
    "        continue\n",
    "\n",
    "    samples = []\n",
    "    if isinstance(s, dict) and 'followers' in s:\n",
    "        samples = list(s.get('followers', {}).values())\n",
    "    else:\n",
    "        samples = [s]\n",
    "\n",
    "    if samples and all(sample.get('disconnected') for sample in samples):\n",
    "        print('All followers disconnected. Stopping GPU loop.')\n",
    "        for sample in samples:\n",
    "            fid = int(sample.get('follower_id', 0))\n",
    "            seq += 1\n",
    "            try:\n",
    "                requests.post(INTRUDER_POST_URL, json={\n",
    "                    'seq': seq,\n",
    "                    'target_id': fid,\n",
    "                    'active': False,\n",
    "                    'speed': 0,\n",
    "                    'length': 0,\n",
    "                    'duration_ms': 0,\n",
    "                }, timeout=3)\n",
    "            except Exception:\n",
    "                pass\n",
    "        break\n",
    "\n",
    "    for sample in samples:\n",
    "        fid = int(sample.get('follower_id', 0))\n",
    "\n",
    "        if sample.get('disconnected'):\n",
    "            if not null_shown.get(fid):\n",
    "                print(f'NULL (leader disconnected) fid={fid}')\n",
    "                null_shown[fid] = True\n",
    "            seq += 1\n",
    "            try:\n",
    "                requests.post(INTRUDER_POST_URL, json={\n",
    "                    'seq': seq,\n",
    "                    'target_id': fid,\n",
    "                    'active': False,\n",
    "                    'speed': 0,\n",
    "                    'length': 0,\n",
    "                    'duration_ms': 0,\n",
    "                }, timeout=3)\n",
    "            except Exception:\n",
    "                pass\n",
    "            continue\n",
    "\n",
    "        null_shown[fid] = False\n",
    "        gap, spd, ttc = compute_block(sample, device=device)\n",
    "\n",
    "        active = gpu_intruder_scan(sample)\n",
    "        seq += 1\n",
    "        try:\n",
    "            requests.post(INTRUDER_POST_URL, json={\n",
    "                'seq': seq,\n",
    "                'target_id': fid,\n",
    "                'active': bool(active),\n",
    "                'speed': INTRUDER_SPEED if active else 0,\n",
    "                'length': INTRUDER_LENGTH if active else 0,\n",
    "                'duration_ms': INTRUDER_DURATION_MS if active else 0,\n",
    "            }, timeout=3)\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "        print(f\"fid={fid} | ts={sample['ts']:.2f} | pos=({sample['my_x']:.1f},{sample['my_y']:.1f}) | speed={sample['current_speed']:.3f} | gap={sample['gap']:.3f} | new_speed={spd:.3f}\")\n",
    "\n",
    "    time.sleep(0.5)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}